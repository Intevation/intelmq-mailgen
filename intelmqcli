#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
TODO: send_email
      process_events
"""
import smtplib
import argparse
import json
import locale
import os
import subprocess
import psycopg2
import psycopg2.extras
from termstyle import red # bold, green, inverted, reset
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication

""" options """
dryrun = False
verbose = False
compress_csv = False
boilerplate = None

if locale.getpreferredencoding() != 'UTF-8':
    print(red('The preferred encoding of your locale setting is not UTF-8 but'
              '{}. Exiting.'.format(locale.getpreferredencoding())))
    exit(1)


# Construct a single configuration dictionary with the contents of the different
# conf files
CONFIG = dict()
home = os.path.expanduser("~")  # needed for OSX
with open(os.path.expanduser(home + '/.intelmq/intelmqcli.conf')) as conf_handle:
    user_config = json.load(conf_handle)
with open('/etc/intelmq/intelmqcli.conf') as conf_handle:
    CONFIG = json.load(conf_handle)

for key, value in user_config.items():
    if key in CONFIG and type(CONFIG[key]) is dict:
        CONFIG[key].update(value)
    else:
        CONFIG[key] = value

EMAIL_FROM = 'noreply@example.com'

APPNAME = "intelmqcli"
DESCRIPTION = """
"""
EPILOG = """
Searches for all unprocessed incidents. Incidents will be filtered by country
code and the TLD of a domain according to configuration.
The search can be restricted to one source feed.

After the start, intelmqcli will immediately connect to RT with the given
credentials. The incidents will be shown grouped by the contact address if
known or the ASN otherwise.

You have 3 options here:
* Select one group by giving the id (number in first column) and show the email
and all events in detail
* Automatic sending of all incidents with 'a'
* Quit with 'q'

For the detailed view, the recipient, the subject and the mail text will be
shown, and below the technical data as csv. If the terminal is not big enough,
the data will not be shown in full. In this case, you can press 't' for the
table mode. less will be opened with the full text and data, whereas the data
will be formated as table, which is much easier to read and interpret.
The requestor (recipient of the mail) can be changed manually by pressing 'r'
and in the following prompt the address is asked. After sending, you can
optionally save the (new) address to the database linked to the ASNs.
If you are ready to submit the incidents to RT and send the mails out, press
's'.
'b' for back jumps to the incident overview and 'q' quits.
"""
USAGE = '''
    intelmqcli
    intelmqcli --dry-run
    intelmqcli --verbose
    intelmqcli --compress-csv
    intelmqcli --list-texts
    intelmqcli --text='boilerplate name'
    intelmqcli --feed='feedname' '''

CON_EVENTDB = psycopg2.connect(database=CONFIG['database']['event']['name'],
                               user=CONFIG['database']['event']['username'],
                               password=CONFIG['database']['event']['password'],
                               host=CONFIG['database']['event']['host'],
                               port=CONFIG['database']['event']['port'],
                               # sslmode=CONFIG['database']['event']['sslmode'],
                               )
CUR_EVENTDB = CON_EVENTDB.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
CON_EVENTDB.autocommit = True

QUERY_GET_EVENTS = """SELECT * FROM events LIMIT 40"""

QUERY_TEXT_NAMES = "SELECT DISTINCT \"key\" from boilerplates"


def shrink_dict(d):
    if not compress_csv:
        return d
    keys = set()
    for line in d:
        keys.update([k for k, v in line.items() if v is not None])
    return [{k: dicti.get(k) for k in keys} for dicti in d]


def getTerminalHeight():
    return int(subprocess.check_output(['stty', 'size']).strip().split()[0])


def send_email(email_event):
    '''
    Sends processed events to the corresponding contacts

    :param email_event: a dictionary with the processed data from an event
    '''
    msg = MIMEMultipart(
        From=EMAIL_FROM,
        To=email_event['email_to'],
        Subject=email_event['subject']
    )
    msg.attach(MIMEText(email_event['email_body']))

    for f in email_event['files'] or []:
        with open(f, "rb") as fil:
            msg.attach(MIMEApplication(
                fil.read(),
                Content_Disposition='attachment; filename="%s"' % os.path.basename(f),
                Name=basename(f)
            ))

    smtp = smtplib.SMTP(server)
    smtp.sendmail(EMAIL_FROM, email_event['email_to'], msg.as_string())
    smtp.close()


def process_events(event_list):
    '''
    Processes each event

    This helper also generates a dictionary that is used when sending the emails

    :param event_list a list of events as created by get_event_list
    '''
    for event in event_list:
        event_email = {}
        event_email['email_to'] = 'contact email'
        event_email['subject'] = 'email subject'

        # The email body. This is generated by combining the template with the
        # event's data and other sources as needed.
        event_email['email_body'] = 'email body'

        # List of files (see format table) to be sent with the email
        event_email['files'] = []
        send_email(event_email)
    pass


def get_event_list():
    '''
    Retrieves the current event list and groups and sorts them
    '''
    CUR_EVENTDB.execute(QUERY_GET_EVENTS)
    event_list = [i for i in CUR_EVENTDB.fetchall()]

    return event_list


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        prog=APPNAME,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        usage=USAGE,
        description=DESCRIPTION,
        epilog=EPILOG,
    )
    parser.add_argument('-L', '--list-texts', action='store_true',
                        help='List all existing texts.')
    parser.add_argument('-a', '--all', action='store_true', help='Process all events (batch mode)')
    parser.add_argument('-f', '--feed', nargs='?', default='%', const='%',
                        help='Show only incidents reported by given feed.')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='Print verbose messages.')
    parser.add_argument('-c', '--compress-csv', action='store_true',
                        help='Automatically compress/shrink the attached CSV report if fields are '
                             'empty (default = False).')
    parser.add_argument('-n', '--dry-run', action='store_true',
                        help='Do not store anything or change anything. Just simulate.')
    args = parser.parse_args()

    if args.verbose:
        verbose = True
    if args.dry_run:
        dryrun = True
    if args.compress_csv:
        compress_csv = True
    if args.text:
        boilerplate = args.text

    event_list = get_event_list()
    while event_list:
        to_process = event_list[:10]
        if not args.all:
            print('Current batch:')
            for i in to_process:
                print('    * {0}'.format(i.get('event_description.text')))

        if args.all:
            answer = 'a'
        else:
            answer = input('Options: [c]ontinue, [s]end this batch, send [a]ll, [q]uit? ')

        if answer == 'c':
            print('Continue')
        elif answer == 's':
            print('Sending this batch')
            event_list[:10] = []
            process_events(to_process)
        elif answer == 'a':
            print('Sending all')
            to_process = event_list[:]
            event_list = []
            process_events(to_process)
        else:
            print('Exiting')
            break

    if args.list_texts:
        CUR_EVENTDB.execute(QUERY_TEXT_NAMES)
        for row in CUR_EVENTDB.fetchall():
            if row['key']:
                print(row['key'])
        exit(0)
